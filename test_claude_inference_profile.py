#!/usr/bin/env python3
"""
Test script ƒë·ªÉ g·ªçi Claude 3.5 Sonnet v2 v·ªõi inference profile
"""

import boto3
import json
import time
from botocore.exceptions import ClientError

def test_claude_with_inference_profile():
    """Test g·ªçi Claude 3.5 Sonnet v2 v·ªõi inference profile"""
    
    # Kh·ªüi t·∫°o Bedrock client v·ªõi profile default
    bedrock_runtime = boto3.client(
        'bedrock-runtime',
        region_name='us-east-1',
        # C√≥ th·ªÉ th√™m profile_name='default' n·∫øu c·∫ßn
    )
    
    # S·ª≠ d·ª•ng inference profile ID thay v√¨ model ID tr·ª±c ti·∫øp
    inference_profile_id = "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    
    # T·∫°o request body
    request_body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 1000,
        "messages": [
            {
                "role": "user",
                "content": "Hello! Can you tell me what model you are and confirm that you're working correctly?"
            }
        ]
    }
    
    try:
        print(f"Testing v·ªõi inference profile: {inference_profile_id}")
        print("ƒêang g·ª≠i request...")
        
        start_time = time.time()
        
        # G·ªçi InvokeModel v·ªõi inference profile
        response = bedrock_runtime.invoke_model(
            modelId=inference_profile_id,  # S·ª≠ d·ª•ng inference profile ID
            body=json.dumps(request_body),
            contentType='application/json',
            accept='application/json'
        )
        
        end_time = time.time()
        latency = end_time - start_time
        
        # Parse response
        response_body = json.loads(response['body'].read())
        
        print(f"‚úÖ SUCCESS!")
        print(f"‚è±Ô∏è  Latency: {latency:.2f} seconds")
        print(f"üìù Response:")
        print(f"   Content: {response_body['content'][0]['text']}")
        print(f"   Input tokens: {response_body['usage']['input_tokens']}")
        print(f"   Output tokens: {response_body['usage']['output_tokens']}")
        
        return True
        
    except ClientError as e:
        print(f"‚ùå AWS Client Error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Unexpected Error: {e}")
        return False

def test_other_models():
    """Test m·ªôt s·ªë model kh√°c ƒë·ªÉ so s√°nh"""
    
    bedrock_runtime = boto3.client(
        'bedrock-runtime',
        region_name='us-east-1'
    )
    
    # Test c√°c inference profile kh√°c
    test_models = [
        {
            "name": "Claude 3.5 Haiku",
            "id": "us.anthropic.claude-3-5-haiku-20241022-v1:0"
        },
        {
            "name": "Nova Lite",
            "id": "us.amazon.nova-lite-v1:0"
        }
    ]
    
    for model in test_models:
        print(f"\n--- Testing {model['name']} ---")
        
        # Request body cho Nova models s·∫Ω kh√°c
        if "nova" in model['id']:
            request_body = {
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "text": f"Hello! I'm testing {model['name']}. Please respond briefly."
                            }
                        ]
                    }
                ],
                "inferenceConfig": {
                    "max_new_tokens": 100
                }
            }
        else:
            # Claude models
            request_body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 100,
                "messages": [
                    {
                        "role": "user",
                        "content": f"Hello! I'm testing {model['name']}. Please respond briefly."
                    }
                ]
            }
        
        try:
            start_time = time.time()
            
            response = bedrock_runtime.invoke_model(
                modelId=model['id'],
                body=json.dumps(request_body),
                contentType='application/json',
                accept='application/json'
            )
            
            end_time = time.time()
            latency = end_time - start_time
            
            response_body = json.loads(response['body'].read())
            
            print(f"‚úÖ {model['name']} - SUCCESS! (Latency: {latency:.2f}s)")
            
            # Parse response based on model type
            if "nova" in model['id']:
                if 'output' in response_body and 'message' in response_body['output']:
                    content = response_body['output']['message']['content'][0]['text']
                    print(f"   Content: {content[:100]}...")
            else:
                if 'content' in response_body:
                    content = response_body['content'][0]['text']
                    print(f"   Content: {content[:100]}...")
            
        except Exception as e:
            print(f"‚ùå {model['name']} - FAILED: {e}")

if __name__ == "__main__":
    print("üß™ Testing AWS Bedrock v·ªõi Inference Profiles")
    print("=" * 50)
    
    # Test Claude 3.5 Sonnet v2
    print("\n1. Testing Claude 3.5 Sonnet v2 v·ªõi inference profile:")
    success = test_claude_with_inference_profile()
    
    if success:
        print("\n2. Testing m·ªôt s·ªë model kh√°c:")
        test_other_models()
    
    print("\n" + "=" * 50)
    print("üèÅ Test completed!")
